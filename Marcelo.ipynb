{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj1WIP2SXxWe"
      },
      "source": [
        "# Preparação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9SZk-16oE8G"
      },
      "source": [
        "## Obtenção dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1D8_i21ZoBSO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/TCC/house_prices/train.csv').drop(\"Id\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozTxxQl2dl5T"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcVbZKwMoE0X"
      },
      "source": [
        "## Limpeza de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iXYvXyYi5MC"
      },
      "source": [
        "### Tratamento de nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHIiNQfRV0Ko"
      },
      "outputs": [],
      "source": [
        "# Verifficando as características com mais valores nulos.\n",
        "top_null = df.isnull().mean().sort_values(ascending=False)*100\n",
        "df_nulos = pd.DataFrame(top_null.values, index = top_null.index,\n",
        "                        columns = ['percentual_nulos'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqYM2kNeWWEE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Gráfico com top 10 nulos\n",
        "\n",
        "threshold = 10\n",
        "mask = np.array(df_nulos['percentual_nulos'][0:10]) > threshold\n",
        "\n",
        "plt.figure(figsize = (12,6))\n",
        "plt.title('top 10 percentual de nulos')\n",
        "ax = sns.barplot(y = df_nulos['percentual_nulos'][0:10],\n",
        "            x = df_nulos.index[0:10],\n",
        "            palette = np.where(mask, '#BD4B5B', '#3288BD'),\n",
        "            errwidth = 0)\n",
        "for i in ax.containers:\n",
        "    ax.bar_label(i,)\n",
        "plt.savefig('top_10_percentual_nulos.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3pjB4nWZdfi"
      },
      "outputs": [],
      "source": [
        "# Remoção de colunas\n",
        "colunas_remocao = df_nulos[df_nulos.percentual_nulos > threshold].index\n",
        "df = df.drop(colunas_remocao, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRWQnYmiZgNK"
      },
      "outputs": [],
      "source": [
        "# Remoção de registros\n",
        "df = df.dropna(axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IedesohhiwRY"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_AB9FZi-kl"
      },
      "source": [
        "### Tratamento de constantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEqQTaYzjBqF"
      },
      "outputs": [],
      "source": [
        "threshold_constante = 90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orCzmFScjkKU"
      },
      "outputs": [],
      "source": [
        "df_constantes = pd.DataFrame()\n",
        "for c in df.columns:\n",
        "    freq_col = df[c].value_counts(normalize=True)*100\n",
        "    if ((freq_col.head(1) > threshold_constante).values[0]):\n",
        "        df_constantes[c] = df[c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6l5lOATmP2U"
      },
      "outputs": [],
      "source": [
        "print(\"Quantidade de dados avaliados como constantes = {qte}\\n\"\\\n",
        "      .format(qte = df_constantes.shape[1]) +\n",
        "      \"Categóricas = {cat}\\n\"\\\n",
        "      .format(cat = df_constantes.select_dtypes(include = ['object']).shape[1])+\n",
        "      \"Numéricas = {num}\\n\"\\\n",
        "      .format(num = df_constantes.select_dtypes(include = ['int64']).shape[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayI6_lrxnkWI"
      },
      "outputs": [],
      "source": [
        "# Remoção\n",
        "df = df.drop(df_constantes.columns, axis = 1)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmFg7w4-Pn8_"
      },
      "source": [
        "## Verificação de multicolinearidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pPD7Kr3Psid"
      },
      "outputs": [],
      "source": [
        "# Instalando biblioteca\n",
        "!pip3 install phik  >/dev/null & echo 'Library Phi K Installed'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5El9j-vvQBeB"
      },
      "outputs": [],
      "source": [
        "# Calculo de Phi K\n",
        "import phik\n",
        "df_phik = df.phik_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7opoEdhOQgTb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(34,20))\n",
        "plt.title(r'Correlação Phi-K ($\\varphi$ K)', fontsize=28)\n",
        "# Construção de uma máscara\n",
        "# Usando Booleanos pois o phi k vai de 0 a 1\n",
        "# Com inteiros deu problema\n",
        "mask = np.triu(np.ones_like(df_phik, dtype = bool))\n",
        "sns.set(font_scale=1.5)\n",
        "htm = sns.heatmap(df_phik, annot=False, mask=mask,\n",
        "                  vmin=0, vmax=1, cmap='vlag',fmt='.2f',)\n",
        "\n",
        "cbar = htm.collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=20)\n",
        "\n",
        "plt.savefig('triu.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crktP81AiRl6"
      },
      "source": [
        "#### Aplicação do Stack para processamento do dataframe\n",
        "![stack figure](https://miro.medium.com/v2/resize:fit:720/format:webp/1*DYDOif_qBEgtWfFKUDSf0Q.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKRydaT2iJ7P"
      },
      "outputs": [],
      "source": [
        "def data_clean_multicolinearity(df , phi_k_corte,target):\n",
        "    # caculando o phik Para o dataFrame\n",
        "    df_phik = df.phik_matrix()\n",
        "\n",
        "    # construção de uma matriz triangular superior para servir de mascara e eliminar duplicados.\n",
        "    mask = np.triu(np.ones_like(df_phik, dtype=bool))\n",
        "\n",
        "    # Aplicação de uma mascara ao dataframe pegando apenas a triangular inferior e removendo a linha do target\n",
        "    df_phi_k_mask = df_phik.mask(mask).drop(target,axis=0)\n",
        "\n",
        "    # Aplicação do Stack\n",
        "    df_phi_k_mask = df_phi_k_mask.stack()\n",
        "\n",
        "    top_phik = df_phi_k_mask[df_phi_k_mask > phi_k_corte]\n",
        "\n",
        "    # Transformo a lista de tuplas em uma lista\n",
        "    feat_phi_k = [item for tupla in top_phik.index for item in tupla]\n",
        "\n",
        "    # Quais são as caracteristicas que mais aparecem\n",
        "    freq_feat_phik = pd.DataFrame(feat_phi_k).value_counts()\n",
        "\n",
        "    # ########################################################################\n",
        "    lst_candidatos = []\n",
        "\n",
        "    #Percorre a lista de pares ordenados\n",
        "    for t in list(top_phik.index):\n",
        "        prim,seg = t[0],t[1]\n",
        "\n",
        "        # SE a frequencia de ocorrencia do primeiro é maio que a do segundo\n",
        "        # E caso o primeiro estja na lista coloca o segundo\n",
        "        if (freq_feat_phik[prim] > freq_feat_phik[seg]):\n",
        "            if (prim not in lst_candidatos):\n",
        "                lst_candidatos.append(prim)\n",
        "            else:\n",
        "                lst_candidatos.append(seg)\n",
        "\n",
        "        elif (freq_feat_phik[seg] > freq_feat_phik[prim]):\n",
        "            if (seg not in lst_candidatos):\n",
        "                lst_candidatos.append(seg)\n",
        "            else:\n",
        "                lst_candidatos.append(prim)\n",
        "        else:\n",
        "            if (prim not in lst_candidatos):\n",
        "                lst_candidatos.append(prim)\n",
        "            else:\n",
        "                lst_candidatos.append(seg)\n",
        "\n",
        "    return df.drop(lst_candidatos,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zSB7M23iKGz"
      },
      "outputs": [],
      "source": [
        "df = data_clean_multicolinearity(df , 0.9,'SalePrice')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjOJap3oW5dk"
      },
      "source": [
        "### Categóricas Ordinais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAnVxdaPXAlE"
      },
      "outputs": [],
      "source": [
        "df.replace(['NA','Po','Fa','TA','Gd','Ex'], [0,1,2,3,4,5],inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afahe4UcW9yZ"
      },
      "source": [
        "### Categóricas Não Ordinais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBbD5moyWmji"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIHwBhXYkQ9q"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE3-y_iMXrCv"
      },
      "source": [
        "# Cálculo da importância de características"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aE4LBTsllpP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZBbf8MXknNr"
      },
      "source": [
        "## Holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqEO2srlXwPl"
      },
      "outputs": [],
      "source": [
        "X, y = df.drop(\"SalePrice\",axis=1), df[\"SalePrice\"]\n",
        "\n",
        "X_train, X_test, \\\n",
        "y_train, y_test = train_test_split(X, y,\n",
        "                                test_size = 0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boOHigNyklfy"
      },
      "source": [
        "## Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF3L4vcAk8Kc"
      },
      "outputs": [],
      "source": [
        "# Parametros para o Túnel\n",
        "param_rf= {'criterion':['squared_error',\\\n",
        "                        'absolute_error',\\\n",
        "                        'friedman_mse'],\n",
        "           'max_depth':[2,3,4,5,7],\n",
        "           'min_samples_split':[2,3,4,5],\n",
        "           'n_estimators':[100,150,200,250,300]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1GFq8QokxVC"
      },
      "outputs": [],
      "source": [
        "# Função com Tunel de hiper parametros.\n",
        "def random_forest_best_params(param,X_train,y_train):\n",
        "    gs_rf = GridSearchCV(RandomForestRegressor(),\n",
        "                             param, scoring='r2',\n",
        "                             n_jobs=-1,cv=5)\n",
        "    gs_rf.fit(X_train, y_train)\n",
        "    return gs_rf.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWtb5vKyl09r"
      },
      "source": [
        "O melhor modelo para métrica R2 Score foi :\n",
        "```\n",
        "{\n",
        "  'criterion': 'squared_error',\n",
        "  'max_depth': 7,\n",
        "  'min_samples_split': 5,\n",
        "  'n_estimators': 100\n",
        "}\n",
        "```\n",
        "Para realizar o teste é só descomentar a linha a baixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SCu3_RPmRAY"
      },
      "outputs": [],
      "source": [
        "#random_forest_best_params(param_rf,X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCoe_stVlbYv"
      },
      "outputs": [],
      "source": [
        "randomforest_r = RandomForestRegressor(criterion = 'squared_error',\n",
        "                               max_depth = 7,\n",
        "                               min_samples_split = 5,\n",
        "                               n_estimators = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7cdNmrrkyBO"
      },
      "source": [
        "## XGBosst Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrqWtB8QlEE5"
      },
      "outputs": [],
      "source": [
        "# Parametros para o Túnel de Params\n",
        "params_xgb = {\\\n",
        "              'n_estimators':[100,150,200,250,300],\n",
        "              'max_depth':[2,3,4,5,6,7,11],\n",
        "               'eta':[0.1,0.2,0.3,0.4,0.5],\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaZKJMqcna8X"
      },
      "outputs": [],
      "source": [
        "def xgb_best_params(params,X_train,y_train):\n",
        "    gs_xgb = GridSearchCV(\n",
        "        XGBRegressor(),\n",
        "        params,\n",
        "        scoring='r2',\n",
        "        n_jobs=-1, cv=5)\n",
        "    gs_xgb.fit(X_train, y_train)\n",
        "    return gs_xgb.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4cBN7synnp0"
      },
      "source": [
        "Entre esses valores o melhor modelo foi:\n",
        "```\n",
        "{\n",
        "    'n_estimators'= 500,\n",
        "    'max_depth' = 2,\n",
        "    'eta' = 0.1\n",
        "}\n",
        "```\n",
        "Para realizar o teste é só descomentar a linha a baixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lt0JEgrn03L"
      },
      "outputs": [],
      "source": [
        "#xgb_best_params(params_xgb,X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY8cLK8on3ez"
      },
      "outputs": [],
      "source": [
        "xgboost_r = XGBRegressor(n_estimators = 500,max_depth = 2, eta = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvBGdEgjo52w"
      },
      "source": [
        "## Validação cruzada 5-fold na métrica R2-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk14sCB_pE8P"
      },
      "outputs": [],
      "source": [
        "rf_reg, xg_reg = randomforest_r, xgboost_r\n",
        "rf_reg.fit(X_train, y_train)\n",
        "xg_reg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7HTRwj6qIie"
      },
      "outputs": [],
      "source": [
        "cv = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSiWh5IUqHFM"
      },
      "outputs": [],
      "source": [
        "rf_scores = cross_val_score(rf_reg, X, y, cv=cv, scoring = 'r2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDuRhSJyp3I2"
      },
      "outputs": [],
      "source": [
        "xgb_scores = cross_val_score(xg_reg, X, y, cv=cv, scoring = 'r2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FNKnqYBp3sV"
      },
      "outputs": [],
      "source": [
        "df_Kfold = pd.DataFrame({\"Random Forest\":rf_scores,\"XGBoost\":xgb_scores})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScRWSe1WqV76"
      },
      "outputs": [],
      "source": [
        "def boxplot_sorted(df, score, title, rot=90, figsize=(10,6), fontsize=12):\n",
        "    df2 = df.T\n",
        "    meds = df2.median().sort_values(ascending=False)\n",
        "    axes = df2[meds.index].boxplot(figsize=figsize, rot=rot, fontsize=fontsize,\n",
        "                                   boxprops=dict(linewidth=4, color='cornflowerblue'),\n",
        "                                   whiskerprops=dict(linewidth=4, color='cornflowerblue'),\n",
        "                                   medianprops=dict(linewidth=4, color='firebrick'),\n",
        "                                   capprops=dict(linewidth=4, color='cornflowerblue'),\n",
        "                                   flierprops=dict(marker='o', markerfacecolor='dimgray',\n",
        "                                        markersize=12, markeredgecolor='black'),\n",
        "                                   return_type=\"axes\")\n",
        "    axes.set_title(title, fontsize=fontsize)\n",
        "    plt.savefig(title + '.pdf')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAIKXnEWqXf0"
      },
      "outputs": [],
      "source": [
        "boxplot_sorted(df_Kfold.T, 'r2', '5-fold in R2 Score', rot=90, figsize=(10,6), fontsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExT-ro-UlEcf"
      },
      "source": [
        "## Shap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ro04zU-sSbN"
      },
      "source": [
        "Essa função roda o SHAP N vezes  com hold-out aleatórios e retorna uma dataframe com resultado de cada rodada.\n",
        "\n",
        "Isto foi realizado para testar a **robustez** dos resultados do SHAP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryllIgrBr39N"
      },
      "outputs": [],
      "source": [
        "!pip install shap >/dev/null & echo \"SHAP Installed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTw6PCWgrxmr"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co2HYCBplIX0"
      },
      "outputs": [],
      "source": [
        "def vet_rand(num):\n",
        "    split = []\n",
        "    count = 0\n",
        "    while (count < num):\n",
        "        n = float(\"{:.2f}\".format( random.random()))\n",
        "        if (n not in split) and n != 0.20 and n < 0.50 and n > 0.10:\n",
        "            split.append(n)\n",
        "            count = count + 1\n",
        "    split.append(0.2)\n",
        "    return split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp4nHGuIrn-F"
      },
      "outputs": [],
      "source": [
        "def evaluate_shap(model, X, y, times = 5):\n",
        "    df = pd.DataFrame()\n",
        "    #split = vet_rand(times)\n",
        "\n",
        "    for t in range(times):\n",
        "        # Hold-out\n",
        "        X_train, X_test,\\\n",
        "        y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "        #y_train, y_test = train_test_split(X, y, test_size = split[t])\n",
        "\n",
        "        # Treinamento do modelo\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Aplicar Shap\n",
        "        explainer = shap.Explainer(model, X_train)\n",
        "        shap_values = explainer(X_train)\n",
        "\n",
        "        # gerando gráficos\n",
        "        if t==0:\n",
        "            #analise global\n",
        "            shap.plots.beeswarm(shap_values, max_display = 21,show=False)\n",
        "            plt.savefig('global_shap_beeswarm.pdf', format='pdf', dpi=600, bbox_inches='tight')\n",
        "            plt.show()\n",
        "\n",
        "            shap.plots.bar(shap_values, max_display = 21, show = False)\n",
        "            plt.savefig('global_shap_bar.pdf', format = 'pdf', dpi = 600, bbox_inches = 'tight')\n",
        "            plt.show()\n",
        "\n",
        "            #analise local\n",
        "            shap.initjs()\n",
        "            shap.plots.force(shap_values[0],matplotlib = True,show = False)\n",
        "            plt.savefig('local_shap_forces.pdf', format = 'pdf', dpi = 600, bbox_inches = 'tight')\n",
        "            plt.show()\n",
        "\n",
        "            shap.plots.waterfall(shap_values[0],max_display = 15, show = False)\n",
        "            plt.savefig('local_shap_waterfall.pdf', format = 'pdf', dpi = 600, bbox_inches = 'tight')\n",
        "            plt.show()\n",
        "\n",
        "            ###\n",
        "            shap.initjs()\n",
        "            shap.plots.force(shap_values[1],matplotlib = True,show = False)\n",
        "            plt.savefig('local_shap_forces1.pdf', format = 'pdf', dpi = 600, bbox_inches = 'tight')\n",
        "            plt.show()\n",
        "\n",
        "            shap.plots.waterfall(shap_values[1],max_display = 15, show = False)\n",
        "            plt.savefig('local_shap_waterfall1.pdf', format = 'pdf', dpi = 600, bbox_inches = 'tight')\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        # Captura das top Features com base no shap\n",
        "        d = { t: [np.abs(i) for i in shap_values.values.mean(axis=0)] }\n",
        "        if t == 0:\n",
        "            df = pd.DataFrame(d)\n",
        "        else:\n",
        "            df = pd.concat([df, pd.DataFrame(d)], axis = 1)\n",
        "\n",
        "    df = df.T\n",
        "    df.columns = [i for i in shap_values.feature_names]\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTURzW86tbxI"
      },
      "outputs": [],
      "source": [
        "shap_n_feat = 20\n",
        "shap_times = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzItzS7Pst7w"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RN00Wsorn8Z"
      },
      "outputs": [],
      "source": [
        "# redução de dimensionalidade para o random forest\n",
        "shap_rf = evaluate_shap(randomforest_r, X, y, shap_times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXUuPh86t1_-"
      },
      "outputs": [],
      "source": [
        "# escolha das 15 caracteristicas globais mais importantes\n",
        "candidatos_rf = list(shap_rf.mean().sort_values(ascending = False)\\\n",
        " [:shap_n_feat].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5YlXYShUh_F"
      },
      "outputs": [],
      "source": [
        "candidatos_rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-V6DTQPswS7"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTqmVPC_szKw"
      },
      "outputs": [],
      "source": [
        "# redução de dimensionalidade para o XGBosst\n",
        "shap_xgb = evaluate_shap(xgboost_r, X, y, shap_times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7GuGaSptVXx"
      },
      "outputs": [],
      "source": [
        "# escolha das N caracteristica mais importantes.\n",
        "candidatos_xgb = list(shap_xgb.mean().sort_values(ascending = False)\\\n",
        "[:shap_n_feat].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNZ1Q_xxUn2n"
      },
      "outputs": [],
      "source": [
        "candidatos_xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0NgdkBmUu9z"
      },
      "source": [
        "## Redução de dimensionalidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMLl0-BwafdC"
      },
      "outputs": [],
      "source": [
        "lista = {\n",
        "    'Random Forest':[randomforest_r, candidatos_rf],\n",
        "    'XGBoost ':[xgboost_r,candidatos_xgb]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QYQxnr_SUnf"
      },
      "outputs": [],
      "source": [
        "def train_and_r2(model,X_train, X_test, y_train, y_test ):\n",
        "    model.fit(X_train, y_train)\n",
        "    # Avaliação do modelo\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = r2_score(y_test, y_pred)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-iu72fDv9-v"
      },
      "outputs": [],
      "source": [
        "## Não mexer\n",
        "def evaluate(models, X, y,label, times = 50):\n",
        "\n",
        "    dicio={}\n",
        "    lst_keys = models.keys()\n",
        "    for i in lst_keys:\n",
        "        dicio[i] = []\n",
        "        dicio[i + ' Reduced'] = []\n",
        "\n",
        "    for i in range(times):\n",
        "\n",
        "        # Hold-out\n",
        "        X_train, X_test, \\\n",
        "        y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
        "\n",
        "        #Para cada modelo faça:\n",
        "        for key in lst_keys:\n",
        "            # treinar o modelo COMPLETO, avaliar e  salvar.\n",
        "            model = models[key][0]\n",
        "            dicio[key].append(train_and_r2(model, X_train, X_test, y_train, y_test))\n",
        "\n",
        "            # treinar o modelo REDUZIDO, avaliar e  salvar.\n",
        "            feat = models[key][1]\n",
        "            dicio[key+ ' Reduced'].append(\n",
        "                train_and_r2(model, X_train[feat], X_test[feat], y_train, y_test))\n",
        "\n",
        "    return pd.DataFrame(dicio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cny1eZMNrpsu"
      },
      "outputs": [],
      "source": [
        "df_r2 = evaluate(lista, X, y,'marcelo')\n",
        "df_r2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rzg2lyRUMgKC"
      },
      "outputs": [],
      "source": [
        "boxplot_sorted(df_r2.T, 'r2', 'Monte carlo CV - 50 times R2-Score', rot=90, figsize=(10,6), fontsize=12)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
